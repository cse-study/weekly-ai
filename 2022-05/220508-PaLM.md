+++

title = "PaLM: Pathway Language Model"
date = "2022-05-08"
[profile]  
	enable = true  
	avatar = "/assets/img/yuho.jpg"  
	name = "Yuho Jeong"  
	github = "yuhodots"
	email = "yuho8437@unist.ac.kr"

+++

Google AI에서 올해 4월에 발표한 Pathway Language Model(PaLM)에 대해 관련 자료를 보고 리뷰합니다.

<!--more-->

### Summary

- Google AI에서 무려 540B 파라미터를 가진 언어 모델을 학습시켰음. 모델 구조는 decoder-only Transformer로 다른 언어 생성 모델들과 큰 차이 없음

1. Pathway: 구글은 2021년에 [pathway](https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture/) 라는 비전을 발표하였고, 이를 이루기 위해서 [pathway system](https://arxiv.org/abs/2203.12533)이라는 가속기 분산 계산 관리 시스템을 개발하였음. Pathway system을 통해 학습된 PaLM은 6144개의 TPU와 1500여 개의 컴퓨터를 통해 학습되었음
2. Chain-of-thought Prompting:  [chain-of-thought prompting](https://arxiv.org/abs/2201.11903.pdf) 방법과 PaLM 모델을 엮어 reasoning 성능을 확연히 높이 수 있었다고 함. Chain-of-thought Prompting은 기존 데이터셋에 대해서 output에 단답이 아닌, 왜 이런 정답이 나왔는지에 대한 intermediate steps을 추가하는 방법임.

### References

- Chowdhery, Aakanksha, et al. "Palm: Scaling language modeling with pathways." arXiv preprint arXiv:2204.02311 (2022).
- [Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance](http://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html)
- [Google's 540B PaLM Language Model & OpenAI's DALL-E 2 Text-to-Image Revolution](https://www.youtube.com/watch?v=RJwPN4qNi_Y)

